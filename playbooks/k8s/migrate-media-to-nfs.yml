---
# Media stack migration playbook
# Migrates media data from Longhorn PVC to NFS storage
# IMPORTANT: Run this after Phase 1-3 are complete

- name: Migrate media stack from Longhorn to NFS
  hosts: control_plane[0]
  gather_facts: false

  vars:
    media_namespace: media
    old_pvc_name: media-stack-data
    new_pv_name: media-stack-nfs
    new_pvc_name: media-stack-nfs
    nfs_server: beelink
    nfs_path: /mnt/storage/media
    storage_capacity: 4Ti

  pre_tasks:
    - name: Display migration information
      ansible.builtin.pause:
        prompt: |
          ╔══════════════════════════════════════════════════════════════╗
          ║            Media Stack NFS Migration                         ║
          ╠══════════════════════════════════════════════════════════════╣
          ║ This playbook will migrate media data from Longhorn to NFS: ║
          ║                                                              ║
          ║ Prerequisites:                                               ║
          ║  ✓ Phase 1: Beelink MergerFS + SnapRAID configured          ║
          ║  ✓ Phase 2: MinIO MergerFS + SnapRAID configured            ║
          ║  ✓ Phase 3: restic backup + SnapRAID automation setup       ║
          ║  ✓ NFS provisioner deployed (make app-deploy APP=nfs-storage)║
          ║                                                              ║
          ║ This migration will:                                        ║
          ║  1. Scale down media stack (0 replicas)                     ║
          ║  2. Create static NFS PV and PVC                            ║
          ║  3. Run rsync job to copy data (Longhorn → NFS)             ║
          ║  4. Verify data integrity                                   ║
          ║                                                              ║
          ║ Time estimate: 1-2 hours (depending on data size)           ║
          ║                                                              ║
          ║ NOTE: Do NOT update app values.yml yet - that comes after!  ║
          ╚══════════════════════════════════════════════════════════════╝

          Press ENTER to continue or Ctrl+C to abort

  tasks:
    # ========================================================================
    # Phase 1: Scale Down Media Stack
    # ========================================================================

    - name: Scale down all media stack deployments
      kubernetes.core.k8s_scale:
        api_version: apps/v1
        kind: Deployment
        name: "{{ item }}"
        namespace: "{{ media_namespace }}"
        replicas: 0
        wait: true
        wait_timeout: 300
      loop:
        - jellyfin
        - radarr
        - sonarr
        - qbittorrent
        - prowlarr
        - jellyseerr

    # ========================================================================
    # Phase 2: Create Static NFS PV
    # ========================================================================

    - name: Create static NFS PersistentVolume
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: "{{ new_pv_name }}"
            labels:
              type: nfs
              app: media-stack
          spec:
            capacity:
              storage: "{{ storage_capacity }}"
            accessModes:
              - ReadWriteMany
            persistentVolumeReclaimPolicy: Retain
            storageClassName: nfs-media
            mountOptions:
              - nfsvers=4.2
              - noatime
              - rsize=1048576
              - wsize=1048576
            nfs:
              server: "{{ nfs_server }}"
              path: "{{ nfs_path }}"

    - name: Create PersistentVolumeClaim for NFS storage
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: "{{ new_pvc_name }}"
            namespace: "{{ media_namespace }}"
            labels:
              app: media-stack
          spec:
            accessModes:
              - ReadWriteMany
            storageClassName: nfs-media
            volumeName: "{{ new_pv_name }}"
            resources:
              requests:
                storage: "{{ storage_capacity }}"

    - name: Wait for PVC to be bound
      kubernetes.core.k8s_info:
        api_version: v1
        kind: PersistentVolumeClaim
        name: "{{ new_pvc_name }}"
        namespace: "{{ media_namespace }}"
      register: pvc_info
      until: pvc_info.resources[0].status.phase == "Bound"
      retries: 30
      delay: 2

    # ========================================================================
    # Phase 3: Data Migration Job
    # ========================================================================

    - name: Create data migration job
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: migrate-media-data
            namespace: "{{ media_namespace }}"
          spec:
            ttlSecondsAfterFinished: 3600  # Clean up after 1 hour
            backoffLimit: 3
            template:
              metadata:
                labels:
                  app: media-migration
              spec:
                restartPolicy: OnFailure
                affinity:
                  nodeAffinity:
                    requiredDuringSchedulingIgnoredDuringExecution:
                      nodeSelectorTerms:
                        - matchExpressions:
                            - key: kubernetes.io/hostname
                              operator: In
                              values:
                                - beelink
                containers:
                  - name: rsync
                    image: instrumentisto/rsync-ssh:latest
                    command:
                      - sh
                      - -c
                      - |
                        echo "==== Media Stack Data Migration ===="
                        echo "Source: /old-data (Longhorn PVC)"
                        echo "Destination: /new-data (NFS storage)"
                        echo ""
                        echo "Starting rsync..."
                        rsync -avh --progress --stats /old-data/ /new-data/
                        RSYNC_EXIT=$?
                        echo ""
                        if [ $RSYNC_EXIT -eq 0 ]; then
                          echo "✓ Migration completed successfully"
                          echo ""
                          echo "Verifying data integrity..."
                          du -sh /old-data /new-data
                          echo ""
                          echo "File counts:"
                          find /old-data -type f | wc -l
                          find /new-data -type f | wc -l
                          echo ""
                          echo "Migration complete!"
                        else
                          echo "✗ Migration failed with exit code $RSYNC_EXIT"
                          exit $RSYNC_EXIT
                        fi
                    volumeMounts:
                      - name: old-data
                        mountPath: /old-data
                        readOnly: true
                      - name: new-data
                        mountPath: /new-data
                    resources:
                      requests:
                        cpu: 100m
                        memory: 256Mi
                      limits:
                        cpu: 1000m
                        memory: 512Mi
                volumes:
                  - name: old-data
                    persistentVolumeClaim:
                      claimName: "{{ old_pvc_name }}"
                  - name: new-data
                    persistentVolumeClaim:
                      claimName: "{{ new_pvc_name }}"

    - name: Wait for migration job to complete
      kubernetes.core.k8s_info:
        api_version: batch/v1
        kind: Job
        name: migrate-media-data
        namespace: "{{ media_namespace }}"
        wait: true
        wait_condition:
          type: Complete
          status: "True"
        wait_timeout: 7200  # 2 hours timeout
      register: migration_job

    - name: Get migration job logs
      kubernetes.core.k8s_log:
        api_version: batch/v1
        kind: Job
        name: migrate-media-data
        namespace: "{{ media_namespace }}"
      register: migration_logs

    - name: Display migration logs
      ansible.builtin.debug:
        msg: "{{ migration_logs.log_lines }}"

    # ========================================================================
    # Phase 4: Verification
    # ========================================================================

    - name: Verify NFS mount on Beelink
      ansible.builtin.command:
        cmd: ssh beelink "ls -lh {{ nfs_path }}"
      delegate_to: localhost
      register: nfs_ls
      changed_when: false

    - name: Display NFS directory listing
      ansible.builtin.debug:
        msg: "{{ nfs_ls.stdout_lines }}"

  post_tasks:
    - name: Display next steps
      ansible.builtin.debug:
        msg: |
          ╔══════════════════════════════════════════════════════════════╗
          ║          Media Stack Migration Complete! ✓                   ║
          ╠══════════════════════════════════════════════════════════════╣
          ║ Migration Summary:                                           ║
          ║  • Old PVC: {{ old_pvc_name }} (Longhorn)                              ║
          ║  • New PVC: {{ new_pvc_name }} (NFS)                                   ║
          ║  • NFS Path: {{ nfs_server }}:{{ nfs_path }}                                     ║
          ║  • Capacity: {{ storage_capacity }}                                          ║
          ║                                                              ║
          ║ Next Steps:                                                  ║
          ║  1. Update media app values.yml files:                       ║
          ║     - apps/radarr/values.yml                                 ║
          ║     - apps/sonarr/values.yml                                 ║
          ║     - apps/jellyfin/values.yml                               ║
          ║     - apps/qbittorrent/values.yml                            ║
          ║                                                              ║
          ║     Change: existingClaim: {{ old_pvc_name }}                          ║
          ║         To: existingClaim: {{ new_pvc_name }}                          ║
          ║                                                              ║
          ║  2. Redeploy media stack:                                    ║
          ║     cd apps/media-stack && make deploy                       ║
          ║                                                              ║
          ║  3. Verify apps are running:                                 ║
          ║     kubectl get pods -n media                                ║
          ║                                                              ║
          ║  4. Test hardlinks still work:                               ║
          ║     kubectl exec -n media deployment/radarr -- \             ║
          ║       sh -c 'touch /data/torrents/test && \                  ║
          ║       ln /data/torrents/test /data/library/test && \         ║
          ║       stat /data/library/test'                               ║
          ║                                                              ║
          ║  5. Once verified, delete old Longhorn PVC:                  ║
          ║     kubectl delete pvc {{ old_pvc_name }} -n media                      ║
          ╚══════════════════════════════════════════════════════════════╝
