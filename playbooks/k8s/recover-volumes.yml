---
# Recover Released Longhorn Volumes After System Restore
#
# This playbook automates the manual PV rebinding process after restoring
# Longhorn System Backup. Without this, apps create new empty volumes instead
# of using the restored data.
#
# Usage:
#   make recover-volumes
#
# When to run:
#   After: make k3s && Longhorn UI System Restore
#   Before: make apps-deploy-all

- name: Recover Released Longhorn Volumes
  hosts: control_plane[0]
  gather_facts: false
  become: true

  vars:
    project_root: "{{ playbook_dir }}/../.."
    shared_pvc_names:
      - media-stack-data

  tasks:
    - name: Get all Longhorn volumes
      kubernetes.core.k8s_info:
        kind: Volume
        api_version: longhorn.io/v1beta2
        namespace: longhorn-system
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      register: longhorn_volumes

    - name: Get all PersistentVolumes
      kubernetes.core.k8s_info:
        kind: PersistentVolume
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      register: all_pvs

    - name: Find Longhorn volumes without PVs
      ansible.builtin.set_fact:
        missing_pvs: "{{ longhorn_volumes.resources |
          selectattr('metadata.name', 'match', '^pvc-') |
          rejectattr('metadata.name', 'in', all_pvs.resources | map(attribute='metadata.name') | list) |
          list }}"

    - name: Initialize PV tracking variables
      ansible.builtin.set_fact:
        released_pvs: []
        available_pvs: []

    - name: Create missing PVs for Longhorn volumes
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolume
          metadata:
            name: "{{ item.metadata.name }}"
            annotations:
              pv.kubernetes.io/provisioned-by: driver.longhorn.io
          spec:
            capacity:
              # Convert bytes to MiB (1 MiB = 1048576 bytes)
              # Using MiB instead of GiB to handle small volumes (e.g., 500Mi)
              # Integer division would round 500Mi to 0Gi, causing validation errors
              storage: "{{ (item.spec.size | int / 1048576) | int }}Mi"
            accessModes:
              - ReadWriteOnce
            persistentVolumeReclaimPolicy: Retain
            storageClassName: longhorn
            csi:
              driver: driver.longhorn.io
              fsType: ext4
              volumeHandle: "{{ item.metadata.name }}"
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      loop: "{{ missing_pvs }}"
      loop_control:
        label: "{{ item.metadata.name }}"
      when: missing_pvs | length > 0

    - name: Display created PVs
      ansible.builtin.debug:
        msg: "✓ Created {{ missing_pvs | length }} missing PV(s) for Longhorn volumes"
      when: missing_pvs | length > 0

    - name: Refresh PV list after creation
      kubernetes.core.k8s_info:
        kind: PersistentVolume
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      register: all_pvs
      when: missing_pvs | length > 0

    - name: Filter Released and Available PVs
      ansible.builtin.set_fact:
        released_pvs: "{{ all_pvs.resources | selectattr('status.phase', 'equalto', 'Released') | list }}"
        available_pvs: "{{ all_pvs.resources | selectattr('status.phase', 'equalto', 'Available') | list }}"
      when: missing_pvs | length > 0

    - name: Display recovery summary
      ansible.builtin.debug:
        msg:
          - "═══════════════════════════════════════════════════════"
          - "Volume Recovery Summary"
          - "═══════════════════════════════════════════════════════"
          - "Total PVs: {{ all_pvs.resources | length }}"
          - "Missing PVs created: {{ missing_pvs | default([]) | length }}"
          - "Released PVs to recover: {{ released_pvs | length }}"
          - "Available PVs (will auto-bind): {{ available_pvs | length }}"
          - "═══════════════════════════════════════════════════════"
      when: missing_pvs | length > 0

    - name: Skip recovery if no Released PVs
      ansible.builtin.debug:
        msg:
          - "✓ No Released PVs found - volumes were restored without claimRef"
          - "✓ {{ available_pvs | length }} Available PVs ready for auto-binding"
          - "✓ Proceed with app deployment - PVCs will bind to existing volumes automatically"
      when: released_pvs | length == 0

    - name: End play if no Released PVs
      ansible.builtin.meta: end_play
      when: released_pvs | length == 0

    - name: Display Released PVs details
      ansible.builtin.debug:
        msg:
          - "PV: {{ item.metadata.name }}"
          - "  Original PVC: {{ item.spec.claimRef.namespace }}/{{ item.spec.claimRef.name }}"
          - "  Size: {{ item.spec.capacity.storage }}"
          - "  StorageClass: {{ item.spec.storageClassName }}"
      loop: "{{ released_pvs }}"

    - name: Validate all Released PVs have claimRef
      ansible.builtin.assert:
        that:
          - item.spec.claimRef is defined
          - item.spec.claimRef.name is defined
          - item.spec.claimRef.namespace is defined
        fail_msg: |
          PV {{ item.metadata.name }} is missing claimRef data. Cannot determine original PVC.
          This PV cannot be automatically recovered. Manual intervention required.
        quiet: true
      loop: "{{ released_pvs }}"
      loop_control:
        label: "{{ item.metadata.name }}"

    - name: Build PVC metadata with release name extraction
      ansible.builtin.set_fact:
        pvc_metadata: "{{ pvc_metadata | default([]) + [{'pv_name': item.metadata.name,
          'pvc_name': item.spec.claimRef.name,
          'namespace': item.spec.claimRef.namespace,
          'storage': item.spec.capacity.storage,
          'access_modes': item.spec.accessModes,
          'storage_class': item.spec.storageClassName,
          'is_shared': (item.spec.claimRef.name in shared_pvc_names),
          'release_from_label': item.metadata.labels['app.kubernetes.io/instance'] | default(''),
          'release_from_name': item.spec.claimRef.name.split('-')[0]}] }}"
      loop: "{{ released_pvs }}"
      loop_control:
        label: "{{ item.spec.claimRef.name }}"

    - name: Determine final release name (with fallback logic)
      ansible.builtin.set_fact:
        pvc_list: >-
          {{ pvc_list | default([]) + [item | combine({'release':
          item.release_from_label if item.release_from_label != ''
          else item.release_from_name})] }}
      loop: "{{ pvc_metadata }}"
      loop_control:
        label: "{{ item.pvc_name }}"

    - name: Display shared PVCs
      ansible.builtin.debug:
        msg: "  - {{ item.namespace }}/{{ item.pvc_name }}"
      loop: "{{ pvc_list | selectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.pvc_name }}"

    - name: Display app-specific PVCs
      ansible.builtin.debug:
        msg: "  - {{ item.namespace }}/{{ item.pvc_name }} (release: {{ item.release }})"
      loop: "{{ pvc_list | rejectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.pvc_name }}"

    - name: Validate app directories exist for app-specific PVCs
      ansible.builtin.stat:
        path: "{{ project_root }}/apps/{{ item.release }}"
      register: app_dir_check
      loop: "{{ pvc_list | rejectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.pvc_name }} -> apps/{{ item.release }}"
      failed_when: not app_dir_check.stat.exists
      when: not item.is_shared

    - name: Display validation result
      ansible.builtin.debug:
        msg:
          - "✅ Validation passed:"
          - "  - All PVs have valid claimRef data"
          - "  - All release names extracted successfully"
          - "  - All app directories exist"
          - ""
          - "Proceeding with recovery..."

    - name: Clear claimRef from Released PVs
      kubernetes.core.k8s_json_patch:
        kind: PersistentVolume
        name: "{{ item.pv_name }}"
        patch:
          - op: remove
            path: /spec/claimRef
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      loop: "{{ pvc_list }}"
      loop_control:
        label: "{{ item.pv_name }}"

    - name: Wait for PVs to become Available
      kubernetes.core.k8s_info:
        kind: PersistentVolume
        name: "{{ item.pv_name }}"
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      register: pv_status
      until: pv_status.resources[0].status.phase == "Available"
      retries: 30
      delay: 2
      loop: "{{ pvc_list }}"
      loop_control:
        label: "{{ item.pv_name }}"

    - name: Extract unique namespaces
      ansible.builtin.set_fact:
        unique_namespaces: "{{ pvc_list | map(attribute='namespace') | unique | list }}"

    - name: Create namespaces if they don't exist
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: "{{ item }}"
            labels:
              name: "{{ item }}"
              managed-by: ansible
        state: present
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      loop: "{{ unique_namespaces }}"

    - name: Delete existing PVCs that might conflict
      kubernetes.core.k8s:
        kind: PersistentVolumeClaim
        name: "{{ item.pvc_name }}"
        namespace: "{{ item.namespace }}"
        state: absent
        kubeconfig: /etc/rancher/k3s/k3s.yaml
        wait: true
        wait_timeout: 60
      loop: "{{ pvc_list }}"
      loop_control:
        label: "{{ item.namespace }}/{{ item.pvc_name }}"
      register: delete_result
      failed_when:
        - delete_result.failed is defined
        - delete_result.failed
        - "'NotFound' not in (delete_result.msg | default(''))"

    - name: Create app-specific PVCs (Helm-managed)
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: "{{ item.pvc_name }}"
            namespace: "{{ item.namespace }}"
            labels:
              app.kubernetes.io/instance: "{{ item.release }}"
              app.kubernetes.io/managed-by: Helm
            annotations:
              helm.sh/resource-policy: keep
          spec:
            accessModes: "{{ item.access_modes }}"
            storageClassName: "{{ item.storage_class }}"
            volumeName: "{{ item.pv_name }}"
            resources:
              requests:
                storage: "{{ item.storage }}"
        state: present
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      loop: "{{ pvc_list | rejectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.namespace }}/{{ item.pvc_name }}"
      register: app_pvc_result

    - name: Create shared PVCs (Ansible-managed)
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: "{{ item.pvc_name }}"
            namespace: "{{ item.namespace }}"
            labels:
              app: media-stack
              managed-by: ansible
          spec:
            accessModes: "{{ item.access_modes }}"
            storageClassName: "{{ item.storage_class }}"
            volumeName: "{{ item.pv_name }}"
            resources:
              requests:
                storage: "{{ item.storage }}"
        state: present
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      loop: "{{ pvc_list | selectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.namespace }}/{{ item.pvc_name }}"
      register: shared_pvc_result

    - name: Wait for PVCs to bind
      kubernetes.core.k8s_info:
        kind: PersistentVolumeClaim
        name: "{{ item.pvc_name }}"
        namespace: "{{ item.namespace }}"
        kubeconfig: /etc/rancher/k3s/k3s.yaml
      register: pvc_status
      until: pvc_status.resources[0].status.phase == "Bound"
      retries: 30
      delay: 2
      loop: "{{ pvc_list }}"
      loop_control:
        label: "{{ item.namespace }}/{{ item.pvc_name }}"

    - name: Display recovery summary header
      ansible.builtin.debug:
        msg:
          - "═══════════════════════════════════════════════════════"
          - "✅ Volume Recovery Complete"
          - "═══════════════════════════════════════════════════════"
          - "Recovered {{ pvc_list | length }} volumes"
          - ""
          - "Helm-Managed PVCs ({{ pvc_list | rejectattr('is_shared') | list | length }}):"

    - name: Display Helm-managed PVCs
      ansible.builtin.debug:
        msg: "  ✓ {{ item.namespace }}/{{ item.pvc_name }} → {{ item.release }} ({{ item.storage }})"
      loop: "{{ pvc_list | rejectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.pvc_name }}"

    - name: Display Ansible-managed header
      ansible.builtin.debug:
        msg:
          - ""
          - "Ansible-Managed PVCs ({{ pvc_list | selectattr('is_shared') | list | length }}):"

    - name: Display Ansible-managed PVCs
      ansible.builtin.debug:
        msg: "  ✓ {{ item.namespace }}/{{ item.pvc_name }} ({{ item.storage }})"
      loop: "{{ pvc_list | selectattr('is_shared') | list }}"
      loop_control:
        label: "{{ item.pvc_name }}"

    - name: Display recovery complete footer
      ansible.builtin.debug:
        msg:
          - "═══════════════════════════════════════════════════════"
          - ""
          - "✅ All PVCs created with proper Helm/Ansible labels"
          - "✅ All PVCs bound to restored Longhorn volumes"
          - ""
          - "Next step: make apps-deploy-all"
          - ""
