---
# Configuration for Beelink ME Mini N150 storage server
# Hardware: Intel N150, 6x M.2 slots, Dual 2.5G LAN
# Role: NFS storage server with MergerFS + SnapRAID for K3s cluster

# Hardware Overview
# ================
# Model: Beelink ME Mini N150
# CPU: Intel N150 (4-core, low power)
# RAM: 12-16GB LPDDR5-4800 (soldered)
# Storage: 6x M.2 slots (2230/2242/2280) - up to 24TB capacity
# Network: Dual 2.5G Ethernet + WiFi 6
# Use case: NFS storage server and media app host for K3s cluster

# ============================================================================
# MergerFS + SnapRAID Configuration
# ============================================================================
# Filesystem-based storage using MergerFS for pooling and SnapRAID for parity.
#
# Benefits:
# - Direct SSH access to files (no need to exec into pods)
# - Reliable backups via restic to MinIO S3
# - Easy expansion (add drives one at a time)
# - Survive single disk failure (SnapRAID parity recovery)
# - Efficient storage (4TB usable with 1 parity drive)

# Storage Drives Configuration
# ============================
storage_drives:
  - device: /dev/disk/by-id/nvme-CT2000P310SSD8_24454C177944
    label: disk1
    mount_point: /mnt/disk1
  - device: /dev/disk/by-id/nvme-CT2000P310SSD8_24454C37CB1B
    label: disk2
    mount_point: /mnt/disk2
  - device: /dev/disk/by-id/nvme-CT2000P310SSD8_24454C40D38E
    label: parity1
    mount_point: /mnt/parity1

# LUKS Encryption Configuration
# =============================
# Full disk encryption for data-at-rest security
luks_key_file: "{{ inventory_dir }}/group_vars/beelink_nas/luks.key"

luks_crypt_devices:
  - name: disk1_crypt
    device: "{{ storage_drives[0].device }}"
  - name: disk2_crypt
    device: "{{ storage_drives[1].device }}"
  - name: parity1_crypt
    device: "{{ storage_drives[2].device }}"

# Filesystem Configuration
# ========================
storage_filesystem: ext4
storage_mount_options: "defaults,noatime"

# MergerFS Configuration
# ======================
# Pool data drives into single mount point for unified storage

mergerfs_mount_point: /mnt/storage

# Data drives to pool (first 2 drives)
mergerfs_data_drives:
  - /mnt/disk1
  - /mnt/disk2

# MergerFS mount options
# - allow_other: Allow non-root users to access
# - use_ino: Preserve inode numbers (required for hardlinks)
# - cache.files=partial: Cache file metadata for performance
# - dropcacheonclose=true: Drop kernel cache when file closed
# - category.create=mfs: Use "most free space" policy for new files
mergerfs_options: "defaults,allow_other,use_ino,cache.files=partial,dropcacheonclose=true,category.create=mfs"

# SnapRAID Configuration
# ======================
# Parity protection for disaster recovery

# Parity file location(s)
snapraid_parity_drives:
  - /mnt/parity1/snapraid.parity

# Data drives configuration
snapraid_data_drives:
  - path: /mnt/disk1
    name: d1
  - path: /mnt/disk2
    name: d2

# Content file locations (metadata storage)
# Multiple locations for redundancy - if one disk fails, metadata survives
snapraid_content_files:
  - /var/snapraid.content
  - /mnt/disk1/.snapraid.content
  - /mnt/disk2/.snapraid.content

# NFS Server Configuration
# ========================
# Export storage to K3s pods for media stack access

nfs_exports:
  # K3s management network (192.168.1.0/24) and pod network (10.42.0.0/16)
  # fsid=1 required for MergerFS exports (NFSv4)
  - path: /mnt/storage
    clients: >-
      192.168.1.0/24(rw,sync,no_subtree_check,no_root_squash,fsid=1)
      10.42.0.0/16(rw,sync,no_subtree_check,no_root_squash,fsid=1)
